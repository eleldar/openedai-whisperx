services:
  server:
    image: whisperx-server
    container_name: WhisperXSever
    build:
      context: .
      dockerfile: Dockerfile
    stdin_open: true
    tty: true
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
      - tempfiles:/app/tempfiles
    restart: no
    runtime: nvidia
    command: python main.py --model openai/whisper-large-v3 --host 0.0.0.0 --port 8000
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              #device_ids: ['0', '1'] # Select a gpu, or
              count: all
              capabilities: [gpu]
volumes:
  tempfiles:
